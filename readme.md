# このリポジトリについて
このリポジトリは課題研究に用いたソースコードを載せておきますが見にくい上に何を使ったかわかりにくいので後日再利用しやすい形に整える予定です。

以下曖昧な記憶で掘り返すファイル解説(作成途中)
## ファイル解説:split.py
 ```
percenta = {100までの数字}
a = "{任意の文字列}"
model = word2vec.Word2Vec.load("{Word2Vecのモデルのパス}")
f = open(R"{テキストファイルのパス}", 'r', encoding='UTF-8') 
 ```
を設定することで分かち書きされたテキストファイル内の単語と変数aの単語の類似度の第percenta百分位数が求まる(気がする)

## ファイル解説:tw.py
* どこからか拾ってきたコードを元にしているのでコメントが付いていますのでそのように(ライセンスが怪しい)
* 28行目↓は出力するファイル名を指定しています
 ```
f = open("./"+search_word+'_tw_data.txt', 'x',encoding="utf_8")
 ```
## ファイル解説:twanalyze.py
```
a = "任意の単語"
b = "任意の単語"
c = "任意の単語"
```
を指定すると
```f = open("./"+search_word+"_tw_data_wakati.txt", 'r', encoding='UTF-8') ```で開かれたファイルの文字列とa,b,c,の単語との類似度の第99,90百分位数が出てくる
